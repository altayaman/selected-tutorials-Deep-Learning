<!DOCTYPE html>
<!-- saved from url=(0037)https://offbit.github.io/how-to-read/ -->
<html class="js no-touchevents cssanimations csstransitions"><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">   <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"> <title>How to read: Character level deep learning – Offbit</title> <meta name="description" content="Bits and pieces from a social robot."> <meta name="keywords" content="dnn, nlp, char-level, rnn"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="https://offbit.github.io/assets/img/logo.png"> <meta name="twitter:title" content="How to read: Character level deep learning"> <meta name="twitter:description" content="How to make character level deep nets for NLP tasks"> <meta name="twitter:site" content="@techabilly"> <meta name="twitter:creator" content="@techabilly"> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="How to read: Character level deep learning"> <meta property="og:description" content="How to make character level deep nets for NLP tasks"> <meta property="og:url" content="https://offbit.github.io/how-to-read/"> <meta property="og:site_name" content="Offbit"> <meta property="og:image" content="https://offbit.github.io/assets/img/logo.png"> <link rel="canonical" href="https://offbit.github.io/how-to-read/"> <link href="https://offbit.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Offbit Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="./How to read_ Character level deep learning – Offbit_files/main.css"> <!-- JS --> <script async="" src="./How to read_ Character level deep learning – Offbit_files/analytics.js"></script><script src="./How to read_ Character level deep learning – Offbit_files/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" href="https://offbit.github.io/assets/img/favicons/apple-icon-precomposed.png"> <link rel="apple-touch-icon" sizes="72x72" href="https://offbit.github.io/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="https://offbit.github.io/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="https://offbit.github.io/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="https://offbit.github.io/favicon.png"> <link rel="shortcut icon" href="https://offbit.github.io/favicon.ico"> <!-- Background Image --> <style type="text/css">body {background-image:url(https://offbit.github.io/assets/img/placeholder-big.jpg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> <style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style id="fit-vids-style">.fluid-width-video-wrapper{width:100%;position:relative;padding:0;}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper object,.fluid-width-video-wrapper embed {position:absolute;top:0;left:0;width:100%;height:100%;}</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head> <body><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-79787749-1', 'auto'); ga('send', 'pageview'); </script> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="https://offbit.github.io/">Home</a></li> <li> <a href="https://offbit.github.io/how-to-read/#">About</a> <ul class="dl-submenu"><li class="dl-back"><a href="https://offbit.github.io/how-to-read/#">back</a></li> <li> <img src="./How to read_ Character level deep learning – Offbit_files/logo.png" alt="Offbit photo" class="author-photo"> <h4>Offbit</h4> <p>Bits and pieces from a social robot.</p> </li> <li><a href="https://offbit.github.io/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="http://twitter.com/techabilly" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a> </li> <li> <a href="http://linkedin.com/in/stathis-vafeias-027682103" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a> </li> <li> <a href="http://instagram.com/techabilly" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-instagram"></i> Instagram</a> </li> <li> <a href="http://github.com/offbit" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> </ul>
<!-- /.dl-submenu --> </li> <li> <a href="https://offbit.github.io/how-to-read/#">Posts</a> <ul class="dl-submenu"><li class="dl-back"><a href="https://offbit.github.io/how-to-read/#">back</a></li> <li><a href="https://offbit.github.io/posts/">All Posts</a></li> <li><a href="https://offbit.github.io/tags/">All Tags</a></li> </ul> </li> <li><a href="https://offbit.github.io/projects/">Projects</a></li> </ul>
<!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title "> <h1>How to read: Character level deep learning</h1> <h4>22 Jun 2016</h4> <p class="reading-time"> <i class="fa fa-clock-o"></i> Reading time ~10 minutes </p>
<!-- /.entry-reading-time --> <a class="btn zoombtn" href="https://offbit.github.io/posts/"> <i class="fa fa-chevron-left"></i> </a> </div> <h1 id="how-to-read-character-level-deep-learning">How to read: Character level deep learning</h1> <p><strong><em>UPDATE 30/03/2017: The repository code has been updated to tf 1.0 and keras 2.0! The repository will not be maintained any more.</em></strong></p> <p>2016, the year of the chat bots. Chat bots seem to be extremely popular these days, every other tech company is announcing some form of intelligent language interface. The truth is that language is everywhere, it’s the way we communicate and the way we manage our thoughts. Most, if not all, of our culture &amp; knowledge is encoded and stored in some language. One can think that if we manage to tap to that source of information efficiently then we are a step closer to create ground breaking knowledge systems. Of course, chat-bots are not even close to “solving” the language problem, after all language is as broad as our thoughts. On the other hand researchers still make useful NLP application that are impressive, like gmail’s <a href="http://arxiv.org/abs/1606.04870">auto-reply</a> or <a href="https://code.facebook.com/posts/181565595577955">deep-text</a> from Facebook.</p> <p>After reading a few papers about NLP, and specifically deep learning applications, I decided to go ahead and try out a few things on my own. In this post I will demonstrate a character level models for sentiment classification. The models are built with my favourite framework <a href="http://keras.io/"><em>Keras</em></a> (with <a href="https://tensorflow.org/">Tensorflow</a> as back-end). In case you haven’t used <em>Keras</em> before I strongly suggest it, it is simple and allows for very fast prototyping (thanks <a href="https://twitter.com/fchollet">François Chollet</a>. After version 1.0 and the introduction of the new functional API, creating complex models can be as easy as a few lines. I’m hoping to demonstrate some of it’s potential as we go along.</p> <p>If you want to get familiar with the framework I would suggest following these links:</p> <ul> <li><a href="http://keras.io/#getting-started-30-seconds-to-keras">30 seconds to <em>Keras</em></a></li> <li><a href="https://github.com/fchollet/keras/tree/master/examples"><em>Keras</em> examples</a></li> <li><a href="http://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html">Building powerful image classification models using very little data</a></li> </ul> <p><strong><em>I also assume that most people reading this have some basic knowledge about convolution networks, mlps, and rnn/lstm models.</em></strong></p> <p>A very popular post from <a href="https://twitter.com/karpathy">Andrej Karpathy</a> talking about the effectiveness of recurrent nets presents a character level language model built with RNNs, find it <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">here</a>. A simple implementation of this model for <em>Keras</em>, <a href="https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py">here</a>.</p> <p>Karpathy’s blog post was probably my first encounter with character level modelling and I have to say I was fascinated by it’s performance. In English character level might not be as appealing as other languages like Greek(my native language). Trying to build vocabularies in Greek can be a bit tricky since words change given the context, so working on character level and letting your model figure out the different word permutations is a very appealing property.</p> <p>If you have a question about a model, the best thing to do with it is experiment. So let’s do it! <script type="text/javascript" src="./How to read_ Character level deep learning – Offbit_files/MathJax.js"></script></p> <h2 id="what-is-a-character-level-model">What is a character level model?</h2> <p>Let’s assume the typical problem of sentiment analysis, given a text, for a example a movie review we need to figure out if the review is positive(1) or negative(0). Let’s denote <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 0.881em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.706em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.584em 1000.71em 2.579em -999.997em); top: -2.222em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="msubsup" id="MathJax-Span-3"><span style="display: inline-block; position: relative; width: 0.706em; height: 0px;"><span style="position: absolute; clip: rect(3.34em 1000.47em 4.16em -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-4" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.471em;"><span class="mi" id="MathJax-Span-5" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.228em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left: 0px solid; width: 0px; height: 0.861em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-1">x_i</script> the text input, which is a sequence of words, and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-6" style="width: 0.881em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.706em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.584em 1000.71em 2.638em -999.997em); top: -2.222em; left: 0em;"><span class="mrow" id="MathJax-Span-7"><span class="msubsup" id="MathJax-Span-8"><span style="display: inline-block; position: relative; width: 0.706em; height: 0px;"><span style="position: absolute; clip: rect(3.34em 1000.41em 4.394em -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-9" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.471em;"><span class="mi" id="MathJax-Span-10" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.228em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left: 0px solid; width: 0px; height: 0.932em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>y</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-2">y_i</script> the corresponding sentiment, so we create a network <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-11" style="width: 2.169em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.759em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.642em 1001.7em 2.93em -999.997em); top: -2.515em; left: 0em;"><span class="mrow" id="MathJax-Span-12"><span class="mi" id="MathJax-Span-13" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.12em;"></span></span><span class="mo" id="MathJax-Span-14" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-15"><span style="display: inline-block; position: relative; width: 0.706em; height: 0px;"><span style="position: absolute; clip: rect(3.34em 1000.47em 4.16em -999.997em); top: -3.978em; left: 0em;"><span class="mi" id="MathJax-Span-16" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span style="position: absolute; top: -3.803em; left: 0.471em;"><span class="mi" id="MathJax-Span-17" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span class="mo" id="MathJax-Span-18" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.52em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left: 0px solid; width: 0px; height: 1.218em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-3">f(x_i)</script> that will predict the label of the sample. In such settings a typical approach is to split the text into a sequence of words, and then learn some fixed length embedding of the sequence that will be used to classify it.</p> <p><img src="./How to read_ Character level deep learning – Offbit_files/lstm.jpg" alt="Simple RNN scheme for sentiment" title="Simple RNN scheme for sentiment classification"></p> <p>In a recurrent model like the above, each word is encoded as a vector (a very nice explanation of word embeddings can be found in Christopher Olah <a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/">blog post</a> - along with an explanatory post for <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTMs</a> - <em>highly recommended reads</em>)</p> <p>Like any typical model that uses a word as it’s smallest input entity, a character level model will use the character as the the smallest entity. E.g: <img src="./How to read_ Character level deep learning – Offbit_files/char-lstm.jpg" alt="Character level RNN" title="character level rnn"></p> <p>This model is reading characters one by one, to create an embedding of the of a given sentence/text. As such our neural network will try to learn that specific sequences of letters form words separated by spaces or other punctuation points. A paper from A. Karpathy &amp; J. Johnson, <a href="http://arxiv.org/abs/1506.02078">“Visualizing and Understanding Recurrent Networks”</a>, demonstrates visually some of the internal processes of char-rnn models.</p> <p>In their paper <a href="https://arxiv.org/pdf/1602.02410.pdf">“Exploring the Limits of Language Modeling”</a>, the Google Brain team show that a character level language model can significantly outperform state of the art models. Their best performing model combines an LSTM with CNN input over the characters, the figure bellow is taken from their paper: <img src="./How to read_ Character level deep learning – Offbit_files/char-cnn-lstm-google.png" alt="cnn lstm" title="cnn lstm"></p> <p>In <a href="https://arxiv.org/pdf/1502.01710v5.pdf">“Text Understanding from Scratch”</a> Zhang et. al. uses pure character level convolution networks to perform text classification with impressive performance. The following figure taken from the paper describes the model: <img src="./How to read_ Character level deep learning – Offbit_files/Selection_001.png" alt="Character level cnn model" title="Char-cnn"></p> <h2 id="building-a-sentiment-model">Building a sentiment model</h2> <p>Let’s try build our model on the popular IMDB review database, the labelled data can be found on this Kaggle competition <a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/data">webpage</a>, we are just going to use the labelled labeledTrainData.tsv which contains 25000 reviews with labels. If you haven’t worked text before, the competition website offers a nice 4-part tutorial to create sentiment prediction models.</p> <p>Our goal is to encode text from character level, so we’ll begin by splitting the text into sentences. Creating sentences from reviews bounds the maximum length of a sequence so it can be easier for our model to handle. After encoding each sentence from characters to a fixed length encoding we use a bi-directional LSTM to read sentence by sentence and create a complete document encoding.</p> <p>The following figure elaborates the full model architecture</p> <p><img src="./How to read_ Character level deep learning – Offbit_files/fullmodel.jpg" alt="Full model"></p> <p>This model starts from reading characters and forming concepts of “words”, then uses a bi-directional LSTM to read “words” as a sequence and account for their position. After that each sentence encoding is being passed through a second bi-directional LSTM that does the final document encoding.</p> <h3 id="preprocessing">Preprocessing</h3> <p>There is minimum preprocessing required for this approach, since our goal is to provide simple text and let the model figure out what that means. So we follow 3 basic steps:</p> <ol> <li>Remove html tags</li> <li>Remove non characters (e.g. weird symbols)</li> <li>Split into sentences</li> </ol> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"labeledTrainData.tsv"</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">quoting</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">txt</span> <span class="o">=</span> <span class="s">''</span>
<span class="n">docs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">cont</span><span class="p">,</span> <span class="n">sentiment</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">review</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">sentiment</span><span class="p">):</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">r'(?&lt;!</span><span class="err">\</span><span class="s">w</span><span class="err">\</span><span class="s">.</span><span class="err">\</span><span class="s">w.)(?&lt;![A-Z][a-z]</span><span class="err">\</span><span class="s">.)(?&lt;=</span><span class="err">\</span><span class="s">.|</span><span class="err">\</span><span class="s">?)</span><span class="err">\</span><span class="s">s'</span><span class="p">,</span> <span class="n">clean</span><span class="p">(</span><span class="n">striphtml</span><span class="p">(</span><span class="n">cont</span><span class="p">)))</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sent</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
    <span class="n">docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
    <span class="n">sentiments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentiment</span><span class="p">)</span></code></pre></figure> <p>The next step is to create a our character set.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
        <span class="n">txt</span> <span class="o">+=</span> <span class="n">s</span>
<span class="n">chars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'total chars:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>
<span class="n">char_indices</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span>
<span class="n">indices_char</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">))</span></code></pre></figure> <p>Create training examples and targets. We bound the maximum length of the sentence to be 512 chars while the maximum number of sentences in a document is bounded at 15. We reverse the order of characters putting the first character at the end of the 512D vector.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">maxlen</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">max_sentences</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">),</span> <span class="n">max_sentences</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sentiments</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">docs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">max_sentences</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">[</span><span class="o">-</span><span class="n">maxlen</span><span class="p">:]):</span>
                <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">maxlen</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">t</span><span class="p">)]</span> <span class="o">=</span> <span class="n">char_indices</span><span class="p">[</span><span class="n">char</span><span class="p">]</span></code></pre></figure> <h3 id="sentence-encoder">Sentence Encoder</h3> <p>We now have our training examples X and the corresponding y target sentiments. X is indexed as (document, sentence, char). The first part of our model is to build a sentence encoder from characters. Using <em>Keras</em> we can do that in a few lines of code.</p> <p>We need to declare a lambda layer that will create a onehot encoding of a sequence of characters on the fly. Holding one-hot encodings in memory is very inefficient.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">binarize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sz</span><span class="o">=</span><span class="mi">71</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sz</span><span class="p">,</span> <span class="n">on_value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">off_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>

<span class="n">filter_length</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">nb_filter</span> <span class="o">=</span> <span class="p">[</span><span class="mi">196</span><span class="p">,</span> <span class="mi">196</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span>
<span class="n">pool_length</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">in_sentence</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int64'</span><span class="p">)</span>
<span class="c"># binarize function creates a onehot encoding of each character index</span>
<span class="n">embedded</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">binarize</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">binarize_outshape</span><span class="p">)(</span><span class="n">in_sentence</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nb_filter</span><span class="p">)):</span>
    <span class="n">embedded</span> <span class="o">=</span> <span class="n">Convolution1D</span><span class="p">(</span><span class="n">nb_filter</span><span class="o">=</span><span class="n">nb_filter</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                            <span class="n">filter_length</span><span class="o">=</span><span class="n">filter_length</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                            <span class="n">border_mode</span><span class="o">=</span><span class="s">'valid'</span><span class="p">,</span>
                            <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span>
                            <span class="n">init</span><span class="o">=</span><span class="s">'glorot_normal'</span><span class="p">,</span>
                            <span class="n">subsample_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span>

    <span class="n">embedded</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span>
    <span class="n">embedded</span> <span class="o">=</span> <span class="n">MaxPooling1D</span><span class="p">(</span><span class="n">pool_length</span><span class="o">=</span><span class="n">pool_length</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span>

<span class="n">forward_sent</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">dropout_W</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout_U</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">consume_less</span><span class="o">=</span><span class="s">'gpu'</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span>
<span class="n">backward_sent</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">dropout_W</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout_U</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">consume_less</span><span class="o">=</span><span class="s">'gpu'</span><span class="p">,</span> <span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span>

<span class="n">sent_encode</span> <span class="o">=</span> <span class="n">merge</span><span class="p">([</span><span class="n">forward_sent</span><span class="p">,</span> <span class="n">backward_sent</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s">'concat'</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sent_encode</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)(</span><span class="n">sent_encode</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">in_sentence</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">sent_encode</span><span class="p">)</span></code></pre></figure> <p>The functional api of <em>Keras</em> allows us to create funky structures with minimum effort. This structure has 3 1DConvolution layers, with relu nonlinearity, 1DMaxPooling and dropout. On top of that there is a bidrectional LSTM (just 2 lines of code).</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">forward_sent</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">dropout_W</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout_U</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">consume_less</span><span class="o">=</span><span class="s">'gpu'</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span>
<span class="n">backward_sent</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">dropout_W</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout_U</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">consume_less</span><span class="o">=</span><span class="s">'gpu'</span><span class="p">,</span> <span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">embedded</span><span class="p">)</span></code></pre></figure> <h3 id="cnn-sentence-encoder">CNN Sentence Encoder</h3> <p>An alternative sentence encoder is one that only uses convolutions and fully connected layers to encode a sentence. The following code composes a network with 2 streams of 3 convolutional layers that operate on different convolutional lengths, after that a temporal max pooling is performed and the 2 streams are concatenated to create a merged vector. The idea behind temporal maxpooling is to identify those <em>features</em> that give a strong sentiment, that could correspond to words like <em>bad</em>, <em>excellent</em>, <em>dislike</em> etc. A temporal max pooling hypothetically will strongly activate some neurons in the sequence, but we do not care about the position of these <em>‘words’</em>, we are only looking for high responses of certain patterns.</p> <p>The following code creates the 2 stream cnn network:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">max_1d</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">char_block</span><span class="p">(</span><span class="n">in_layer</span><span class="p">,</span> <span class="n">nb_filter</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="n">filter_length</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">subsample</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pool_length</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">in_layer</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nb_filter</span><span class="p">)):</span>

        <span class="n">block</span> <span class="o">=</span> <span class="n">Convolution1D</span><span class="p">(</span><span class="n">nb_filter</span><span class="o">=</span><span class="n">nb_filter</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                              <span class="n">filter_length</span><span class="o">=</span><span class="n">filter_length</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                              <span class="n">border_mode</span><span class="o">=</span><span class="s">'valid'</span><span class="p">,</span>
                              <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span>
                              <span class="n">subsample_length</span><span class="o">=</span><span class="n">subsample</span><span class="p">[</span><span class="n">i</span><span class="p">])(</span><span class="n">block</span><span class="p">)</span>
        <span class="c"># block = BatchNormalization()(block)</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)(</span><span class="n">block</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pool_length</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">block</span> <span class="o">=</span> <span class="n">MaxPooling1D</span><span class="p">(</span><span class="n">pool_length</span><span class="o">=</span><span class="n">pool_length</span><span class="p">[</span><span class="n">i</span><span class="p">])(</span><span class="n">block</span><span class="p">)</span>

    <span class="n">block</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">max_1d</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="n">nb_filter</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],))(</span><span class="n">block</span><span class="p">)</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span>

<span class="n">in_sentence</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int64'</span><span class="p">)</span>
<span class="n">embedded</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">binarize</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">binarize_outshape</span><span class="p">)(</span><span class="n">in_sentence</span><span class="p">)</span>

<span class="n">block2</span> <span class="o">=</span> <span class="n">char_block</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="n">filter_length</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">subsample</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pool_length</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">block3</span> <span class="o">=</span> <span class="n">char_block</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span> <span class="n">filter_length</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">subsample</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pool_length</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">sent_encode</span> <span class="o">=</span> <span class="n">merge</span><span class="p">([</span><span class="n">block2</span><span class="p">,</span> <span class="n">block3</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s">'concat'</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sent_encode</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)(</span><span class="n">sent_encode</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">in_sentence</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">sent_encode</span><span class="p">)</span></code></pre></figure> <h3 id="document-encoder">Document Encoder</h3> <p>The sentence encoder feeds it’s output to a document encoder that is composed of a bidirectional lstm with fully connected layers at the top.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">sequence</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">max_sentences</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int64'</span><span class="p">)</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">encoder</span><span class="p">)(</span><span class="n">sequence</span><span class="p">)</span>
<span class="n">forwards</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">dropout_W</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout_U</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">consume_less</span><span class="o">=</span><span class="s">'gpu'</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
<span class="n">backwards</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">dropout_W</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">dropout_U</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">consume_less</span><span class="o">=</span><span class="s">'gpu'</span><span class="p">,</span> <span class="n">go_backwards</span><span class="o">=</span><span class="bp">True</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>

<span class="n">merged</span> <span class="o">=</span> <span class="n">merge</span><span class="p">([</span><span class="n">forwards</span><span class="p">,</span> <span class="n">backwards</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s">'concat'</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)(</span><span class="n">merged</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)(</span><span class="n">output</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">sequence</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">)</span></code></pre></figure> <p>The <em>TimeDistributed</em> layer is what allows the model to run a copy of the <em>encoder</em> to every sentence in the document. The final output is a sigmoid function that predicts 1 for positive, 0 for negative sentiment.</p> <p>The model is trained with an cnn/bi-lstm encoder on 20000 reviews and validating on 2500 reviews. The optimzer used is adam with the default parameters. The model roughly achieves ~86% accuarcy on the validation in the first 15 epochs. (<em>Note</em>: A sligthly different architecture with a two stream cnn sentence net performs similarly)</p> <p><img src="./How to read_ Character level deep learning – Offbit_files/doc-rnn.png" alt="Training Model" title="Char-cnn"></p> <p>After the 15 epochs the model’s improvement on the validation set is stalling but still increases performance on the training set. A better tuned model would probably overcome this but the purpose of this post is to demonstrate how create character level models and not achieve the best possible result. Some things that might improve the generalisation and reduce overfitting:</p> <ul> <li> <p>Different hidden layer sizes, smaller layers will reduce the abillity of the model to overfit to the training set.</p> </li> <li> <p>Larger dropout rates.</p> </li> <li> <p>l2/l1 regularization.</p> </li> <li> <p>A deeper and/or wider architecture of cnn encoder.</p> </li> <li> <p>Different doc encoder, maybe include an attention module?</p> </li> </ul> <p>All of the code can be found in my github repository: <a href="https://github.com/offbit/char-models">https://github.com/offbit/char-models</a></p> <h3 id="final-words">Final words</h3> <p>I really enjoy the idea of creating character level models, there is something appealing in creating models that work on such level. Character level modelling enables us to deal with common miss-spellings, different permutation of words (think run, runs, running) that are even more common in some other languages. I’m also expecting to work better in text that contains, emojis, signaling chars, hashtags and all the funky annotations that are being used in social media. In the best of my knowledge I haven’t seen results of char-level models in twitter data for example, but I’m guessing twitter/fb/google already test these things in large social media uncurated corpus. Some of the aforementioned papers already show promising results, and given enough data character level models shine.</p> <p>If you liked my post drop me a line at twitter <a href="https://twitter.com/techabilly">@techabilly</a>, or email: s.vafeias_at_gmail .</p> <div class="entry-meta"> <br> <hr> <span class="entry-tags"><a href="https://offbit.github.io/tags/#dnn" title="Pages tagged dnn" class="tag"><span class="term">dnn</span></a><a href="https://offbit.github.io/tags/#nlp" title="Pages tagged nlp" class="tag"><span class="term">nlp</span></a><a href="https://offbit.github.io/tags/#char-level" title="Pages tagged char-level" class="tag"><span class="term">char-level</span></a><a href="https://offbit.github.io/tags/#rnn" title="Pages tagged rnn" class="tag"><span class="term">rnn</span></a></span> <span class="social-share"> <a href="https://www.facebook.com/sharer/sharer.php?u=https://offbit.github.io/how-to-read/" title="Share on Facebook" class="tag"> <span class="term"><i class="fa fa-facebook-square"></i> Like</span> </a> <a href="https://twitter.com/intent/tweet?text=https://offbit.github.io/how-to-read/" title="Share on Twitter" class="tag"> <span class="term"><i class="fa fa-twitter-square"></i> Tweet</span> </a> <a href="https://plus.google.com/share?url=https://offbit.github.io/how-to-read/" title="Share on Google+" class="tag"> <span class="term"><i class="fa fa-google-plus-square"></i> +1</span> </a> </span> <div style="clear:both"></div> </div> </div> </div> </header> <!-- JS --> <script src="./How to read_ Character level deep learning – Offbit_files/jquery-1.12.0.min.js"></script> <script src="./How to read_ Character level deep learning – Offbit_files/jquery.dlmenu.min.js"></script> <script src="./How to read_ Character level deep learning – Offbit_files/jquery.goup.min.js"></script> <script src="./How to read_ Character level deep learning – Offbit_files/jquery.magnific-popup.min.js"></script> <script src="./How to read_ Character level deep learning – Offbit_files/jquery.fitvid.min.js"></script> <script src="./How to read_ Character level deep learning – Offbit_files/scripts.js"></script> <!-- MathJax --> <script async="" src="./How to read_ Character level deep learning – Offbit_files/MathJax(1).js" type="text/javascript"></script>  
<div style="position: fixed; width: 40px; height: 40px; background: rgb(255, 255, 255); cursor: pointer; bottom: 10px; right: 20px; border-radius: 0px; display: none;" class="goup-container" title=""><div class="goup-arrow" style="width: 0px; height: 0px; margin: 0px auto; padding-top: 13px; border-style: solid; border-width: 0px 10px 10px; border-color: transparent transparent rgb(0, 0, 0);"></div></div><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: STIXSizeOneSym, sans-serif;"></div></div></body></html>